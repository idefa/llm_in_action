{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc1e637",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hugging Faceä»‹ç»\n",
    "Hugging Faceï¼ˆç®€ç§°HFï¼Œ[å®˜ç½‘åœ°å€](https://huggingface.co/)ï¼‰æœ€å¼€å§‹æ˜¯ä¸“æ³¨äºNLPæŠ€æœ¯çš„å¤§å‹å¼€æºç¤¾åŒºï¼Œåœ¨githubä¸Šå¼€æºçš„è‡ªç„¶è¯­è¨€å¤„ç†é¢„è®­ç»ƒæ¨¡å‹åº“Transformerså·²è¢«ä¸‹è½½è¶…è¿‡ç™¾ä¸‡æ¬¡ï¼Œgithubä¸Šè¶…è¿‡64000é¢—æ˜Ÿã€‚æä¾›å¤§é‡çš„start-of-artçš„é¢„è®­ç»ƒæ¨¡å‹æ˜¯HFçš„æœ€å¤§æ‹›ç‰Œï¼Œç›®å‰å·²ç»è¦†ç›–äº†NLPã€CVã€Audioã€Multimodelç­‰é¢†åŸŸçš„ä¸Šä¸‡ä¸ªæ¨¡å‹ï¼Œä¸ºå¹¿å¤§æ¨¡å‹å¼€å‘è€…ã€ç ”ç©¶è€…å’Œç®—æ³•å·¥ç¨‹å¸ˆæä¾›äº†æå¤§çš„ä¾¿åˆ©ã€‚\n",
    "\n",
    "HFæœ€ä¸»è¦çš„ç‰¹æ€§åŒ…æ‹¬ï¼š\n",
    "  * å¤§é‡çš„é¢„è®­ç»ƒæ¨¡å‹\n",
    "  * æ¨¡å‹ç›´æ¥æ”¯æŒæ¨ç†å’ŒFineTune\n",
    "  * ç®€æ´çš„python sdk\n",
    "  * å®Œå–„çš„åŸºäºgitå’Œgit lfsçš„ModelHub\n",
    "  * åŒæ—¶æ”¯æŒTensorflow 2.0+ï¼ŒPyTroch 1.1.0+ å’ŒFlax\n",
    "\n",
    "ä½¿ç”¨HFï¼Œä»»ä½•äººéƒ½å¯ä»¥åœ¨æœ€å¿«çš„æ—¶é—´å†…è·å¾—å·¥ä¸šç•Œæœ€çŸ¥åçš„é¢„è®­ç»ƒæ¨¡å‹ç”¨äºè‡ªå·±çš„ç ”ç©¶æˆ–è€…ç”Ÿäº§ã€‚ä¸‹é¢ä»‹ç»å¦‚ä½•ä½¿ç”¨python sdkè®¿é—®HFã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfbb78",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "HFçš„åŠŸèƒ½ä¸»è¦é€šè¿‡3ä¸ªpython packageæ¥å®Œæˆï¼š\n",
    " * transformers\n",
    " * datasets\n",
    " * tokenizers\n",
    " * huggingface_hub\n",
    " \n",
    "å®ƒä»¬éƒ½å¯ä»¥é€šè¿‡pipæ¥å®‰è£…ï¼Œè¦æ±‚pythonç¯å¢ƒæ˜¯3.6+ã€‚ä½¿ç”¨transformerséœ€è¦æ³¨æ„å¯¹Tensorflowå’ŒPyTorchçš„ä¾èµ–ï¼ŒHFä¸­çš„æ¨¡å‹å¡ç‰‡ä¸­ä¼šæ ‡æ˜èƒ½å¤Ÿæ”¯æŒå“ªç§æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚æœ¬æ–‡ä¸­å‡è®¾PyTorchå·²ç»å®‰è£…ï¼Œä¹Ÿå¯ä»¥åœ¨DSWçš„é•œåƒåˆ—è¡¨ä¸­é€‰å–é¢„è£…pytrochçš„é•œåƒæˆ–è€…åœ¨ç¯å¢ƒä¸­æ˜¾å¼çš„å®‰è£…PyTorchã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ad7be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets tokenizers huggingface_hub sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da177e8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32b62c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6423fd29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¾—åˆ°ç»“æœï¼š`[{'label': 'POSITIVE', 'score': 0.9998704195022583}]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54024b63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. ä½¿ç”¨HFçš„pipelineåšæ¨ç†\n",
    "HFæŠŠå„ç§æ¨¡å‹å®‰è£…ä»»åŠ¡ï¼ˆTaskï¼‰åšäº†åˆ†ç±»ï¼Œé’ˆå¯¹æ¯ä¸€ç±»Taskï¼ŒHFä¼šæä¾›è°ƒç”¨çš„æ ‡å‡†æ–¹æ³•ï¼Œä»¥åŠé»˜è®¤çš„æ¨¡å‹ã€‚HFæŠŠæ¨ç†çš„ä»»åŠ¡å°è£…åˆ°pipelineå¯¹è±¡ä¸­ï¼Œå› ä¸ºä¸€ä¸ªæ¨ç†ä»»åŠ¡é€šå¸¸æ¶‰åŠåˆ°3ä¸ªæ­¥éª¤ï¼šæŠŠè¾“å…¥æ•°æ®åšåˆ†è¯å¹¶è½¬æ¢ä¸ºIDï¼Œè°ƒç”¨æ¨¡å‹çš„é¢„æµ‹å‡½æ•°ï¼ŒæŠŠIDè½¬æ¢ä¸ºè¯æ±‡è¡¨ä¸­çš„æ–‡æœ¬ã€‚\n",
    "\n",
    "### 2.1 è‹±æ–‡æƒ…æ„Ÿåˆ†æ\n",
    "sentiment-analysisæ˜¯ä¸€ä¸ªæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼šç»™å®šä¸€æ®µæ–‡å­—ï¼Œç»™å‡ºæ˜¯æ­£é¢è¿˜æ˜¯è´Ÿé¢çš„è¯„ä»·ã€‚HFä¼šä½¿ç”¨é»˜è®¤çš„æ¨¡å‹æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3812cb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "results = classifier([\"PAI is a wonderful tool for AI development\", \"It's a rainy day.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd4370",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¾—åˆ°ç»“æœï¼š \n",
    "```label: POSITIVE, with score: 0.9998```\n",
    "\n",
    "```label: NEGATIVE, with score: 0.9964```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef25dfe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 ä¸­æ–‡é—®é¢˜å›ç­”ï¼ˆExtractive Q&Aï¼‰\n",
    "pipelineçš„æ„é€ å‡½æ•°ä¸­å¯ä»¥æŒ‡å®šHFä»“åº“ä¸­çš„æ¨¡å‹åå­—æ¥å®Œæˆç‰¹å®šä»»åŠ¡ã€‚åœ¨HFä¸­ï¼Œä½¿ç”¨language=zhï¼Œtask=question-answeringè¿‡æ»¤ï¼Œçœ‹åˆ°æ’åç¬¬ä¸€çš„æ¨¡å‹æ˜¯â€œuer/roberta-base-chinese-extractive-qaâ€ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒæ¥å®ŒæˆQ&Aä»»åŠ¡ï¼šç»™å®šä¸€æ®µæ–‡æœ¬å’Œé—®é¢˜ï¼Œè·å–ç­”æ¡ˆï¼›è¿™é‡Œçš„ç­”æ¡ˆä»…ä»…æ˜¯ä»æ–‡æœ¬ä¸­ï¼ˆè¢«ç§°ä¸ºcontextï¼‰æŠ½å–ä¸€æ®µæ–‡æœ¬ï¼Œæ‰€ä»¥åªéœ€è¦è¿”å›ä¸€ä¸ªstartå’Œendçš„ä¸‹æ ‡ï¼Œç”¨æ¥æ ‡è¯†å‡ºç­”æ¡ˆï¼ŒExtractive Question Answeringã€‚è¿™ä¸ªæ¨¡å‹æ˜¯åŸºäº[chinese_roberta_L-12_H-768](https://huggingface.co/uer/chinese_roberta_L-12_H-768)ï¼Œå†ä¸“é—¨é’ˆå¯¹3ä¸ªä¸­æ–‡è¯­æ–™åº“åšçš„FineTuneå¾—åˆ°çš„æ¨¡å‹ï¼šå…¨å›½ç¬¬äºŒå±Šâ€œå†›äº‹æ™ºèƒ½æœºå™¨é˜…è¯»â€æŒ‘æˆ˜èµ›ï¼Œç™¾åº¦çš„ä¸­æ–‡é—®ç­”æ•°æ®é›†WebQAï¼Œç¬¬äºŒå±Šâ€œè®¯é£æ¯â€ä¸­æ–‡æœºå™¨é˜…è¯»ç†è§£è¯„æµ‹CMRC 2018å…¬å¼€æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2983ceec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo: {\n",
       "\tmodelId: uer/roberta-base-chinese-extractive-qa\n",
       "\tsha: d5e37a8228fa9d396ff4b093c21e8f0082ff11e1\n",
       "\tlastModified: 2022-02-20T07:50:56.000Z\n",
       "\ttags: ['pytorch', 'tf', 'jax', 'bert', 'question-answering', 'zh', 'transformers', 'autotrain_compatible', 'infinity_compatible']\n",
       "\tpipeline_tag: question-answering\n",
       "\tsiblings: [ModelFile(rfilename='.gitattributes'), ModelFile(rfilename='README.md'), ModelFile(rfilename='config.json'), ModelFile(rfilename='flax_model.msgpack'), ModelFile(rfilename='pytorch_model.bin'), ModelFile(rfilename='special_tokens_map.json'), ModelFile(rfilename='tf_model.h5'), ModelFile(rfilename='tokenizer_config.json'), ModelFile(rfilename='vocab.txt')]\n",
       "\tconfig: None\n",
       "\tid: uer/roberta-base-chinese-extractive-qa\n",
       "\tprivate: False\n",
       "\tauthor: uer\n",
       "\tdownloads: 4779\n",
       "\tlibrary_name: transformers\n",
       "\tlikes: 11\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_models, ModelFilter\n",
    "\n",
    "# è·å–æ‰€æœ‰æ”¯æŒä¸­æ–‡çš„é—®ç­”ç±»æ¨¡å‹\n",
    "models = list_models(filter=ModelFilter(task=\"question-answering\", language=\"zh\"))\n",
    "models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1bd57",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¯ä»¥çœ‹åˆ°ä¸HFçš„å®˜ç½‘ç½‘ç«™ä¸Šçš„æ•ˆæœæ˜¯ä¸€è‡´çš„ï¼š\n",
    "\n",
    "```{figure} ./_html/hf1.png\n",
    ":width: 50%\n",
    "\n",
    "Fig.1 - hugging face\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4ee8c0ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9766426086425781, 'start': 0, 'end': 3, 'answer': 'æ™®å¸Œé‡‘'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer,pipeline\n",
    "\n",
    "# ä½¿ç”¨AutoModelFor<TASK>æ¥æ˜¾ç¤ºé€‰å–æ¨¡å‹\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('uer/roberta-base-chinese-extractive-qa')\n",
    "\n",
    "# NLPæ¨¡å‹ä¸€èˆ¬éƒ½éœ€è¦ä¸€ä¸ªTokenizeræ¥åˆ‡è¯ï¼Œè€Œæ¨¡å‹æä¾›æ–¹ä¼šæœ‰å¯¹åº”çš„å‡†å¤‡\n",
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-chinese-extractive-qa')\n",
    "QA = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "QA_input = {'question': \"è‘—åè¯—æ­Œã€Šå‡å¦‚ç”Ÿæ´»æ¬ºéª—äº†ä½ ã€‹çš„ä½œè€…æ˜¯\",\n",
    "            'context': \"æ™®å¸Œé‡‘ä»é‚£é‡Œå­¦ä¹ äººæ°‘çš„è¯­è¨€ï¼Œå¸å–äº†è®¸å¤šæœ‰ç›Šçš„å…»æ–™ï¼Œè¿™ä¸€åˆ‡å¯¹æ™®å¸Œé‡‘åæ¥çš„åˆ›ä½œäº§ç”Ÿäº†å¾ˆå¤§çš„å½±å“ã€‚\"\n",
    "                       \"è¿™ä¸¤å¹´é‡Œï¼Œæ™®å¸Œé‡‘åˆ›ä½œäº†ä¸å°‘ä¼˜ç§€çš„ä½œå“ï¼Œå¦‚ã€Šå›šå¾’ã€‹ã€ã€Šè‡´å¤§æµ·ã€‹ã€ã€Šè‡´å‡¯æ©ã€‹å’Œã€Šå‡å¦‚ç”Ÿæ´»æ¬ºéª—äº†ä½ ã€‹ç­‰å‡ åé¦–æŠ’æƒ…è¯—ï¼Œ\"\n",
    "                       \"å™äº‹è¯—ã€ŠåŠªæ—ä¼¯çˆµã€‹ï¼Œå†å²å‰§ã€Šé²é‡Œæ–¯Â·æˆˆéƒ½è¯ºå¤«ã€‹ï¼Œä»¥åŠã€Šå¶ç”«ç›–å°¼Â·å¥¥æ¶…é‡‘ã€‹å‰å…­ç« ã€‚\"}\n",
    "QA(QA_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "31d8230f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0009129824466072023, 'start': 0, 'end': 2, 'answer': 'åŒ—äº¬'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_input = {'question': \"ä¸­å›½çš„é¦–éƒ½æ˜¯\",\n",
    "            'context': \"åŒ—äº¬æ˜¯ä¸€ä¸ªå¤è€çš„åŸå¸‚ï¼Œä»1949å¹´èµ·æˆä¸ºæ–°ä¸­å›½çš„é¦–éƒ½ã€‚åœ¨æŠ—æ—¥æˆ˜äº‰æ—¶æœŸï¼Œé‡åº†æ›¾ç»æˆä¸ºé™ªéƒ½ã€‚\"}\n",
    "QA(QA_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da5693",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 3. åŸºäºé¢„è®­ç»ƒçš„æ¨¡å‹åšFineTune\n",
    "\n",
    "FineTuneæˆ–è€…Transfer Learningæ˜¯ä¸€ç§æ¯”è¾ƒæµè¡Œçš„åšæ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨NLPé¢†åŸŸï¼šåˆ©ç”¨å¤§é‡çš„è¯­æ–™è®­ç»ƒå‡ºä¸€ä¸ªåŸºæœ¬çš„æ¨¡å‹ï¼Œç„¶ååœ¨ç»“åˆè‡ªå·±çš„ä¸šåŠ¡æ•°æ®ï¼Œå†åŸºæœ¬æ¨¡å‹ä¹‹ä¸Šè¿›ä¸€æ­¥FineTuneã€‚HFä¸­æœ‰ä¸‰ç§æ–¹æ³•æ¥è¿è¡ŒFine-Tuneçš„è®­ç»ƒè¿‡ç¨‹([å®˜æ–¹é“¾æ¥](https://huggingface.co/docs/transformers/training))ï¼š\n",
    "* Fine-tune a pretrained model with ğŸ¤— Transformers Trainer.\n",
    "* Fine-tune a pretrained model in TensorFlow with Keras.\n",
    "* Fine-tune a pretrained model in native PyTorch.\n",
    "\n",
    "FineTuneæ˜¯åœ¨é¢„è®­ç»ƒçš„æ¨¡å‹çš„æƒé‡åŸºç¡€ä¹‹ä¸Šï¼Œè¿›ä¸€æ­¥è®­ç»ƒï¼Œæœ‰ä¸¤ç§æƒ…å†µï¼š\n",
    "1. é¢„è®­ç»ƒå¥½çš„æ¨¡å‹å·²ç»å¯ä»¥è§£å†³ç›®å‰çš„é—®é¢˜ï¼Œä½†æ˜¯éœ€è¦æŠŠæ¨¡å‹æƒé‡è¿›ä¸€æ­¥è®­ç»ƒä»¥é€‚åº”æ–°çš„è®­ç»ƒæ ·æœ¬ã€‚\\\n",
    "ä¸€ä¸ªå…¸å‹ä¾‹å­æ˜¯é€šç”¨çš„é¢„è®­ç»ƒè‹±æ–‡ç¿»è¯‘æ¨¡å‹ï¼Œåœ¨å¤§é‡çš„é€šç”¨è¯­æ–™ä¸Šè®­ç»ƒè€Œæ¥ï¼›ä½†æ˜¯é’ˆå¯¹æŸä¸ªä¸“ä¸šé¢†åŸŸæ•ˆæœä¸æ˜¯å¾ˆç†æƒ³ã€‚å¦‚æœæˆ‘ä»¬æ‹¥æœ‰è¿™ä¸ªé¢†åŸŸçš„è¯­æ–™ï¼Œå¯ä»¥è¿›ä¸€æ­¥è®­ç»ƒï¼Œä½¿å¾—åœ¨è¿™ä¸ªé¢†åŸŸçš„æ•ˆæœå¾—åˆ°æ”¹è¿›ã€‚\n",
    "2. é¢„è®­ç»ƒæ¨¡å‹çš„ç½‘ç»œç»“æ„ä¸èƒ½ç›´æ¥è§£å†³å½“å‰é—®é¢˜ï¼Œè¿›åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„æœ€ä¸»è¦ç½‘ç»œéƒ¨åˆ†ï¼Œç„¶åå¢åŠ é’ˆå¯¹æ–°ä»»åŠ¡çš„ç¥ç»ç½‘ç»œlayerï¼›è¿™ä¸ªæ—¶å€™çš„FineTuneæ˜¯æŠŠåŸæ¨¡å‹çš„ä¸»è¦éƒ¨åˆ†æƒé‡å·²ç»æ–°å¢åŠ çš„layerçš„æƒé‡ä¸€èµ·è®­ç»ƒã€‚\\\n",
    "æ¯”å¦‚æˆ‘ä»¬ç”¨ä¸€ä¸ªæ™®é€šçš„bertè¯­è¨€æ¨¡å‹æ¥åšQuestionAnsweringï¼ŒHFå°±ä¼šæç¤ºåŸæœ‰çš„éƒ¨åˆ†æ¨¡å‹æƒé‡æ²¡æœ‰è¢«ä½¿ç”¨ï¼ŒåŒæ—¶æœ‰ä¸€éƒ¨åˆ†æƒé‡æ²¡æœ‰è¢«åˆå§‹åŒ–ã€‚è¿™æ˜¯å› ä¸ºé¢„è®­ç»ƒå¥½çš„æ¨¡å‹çš„çš„ç½‘ç»œç»“æ„æ˜¯Embedding->Transoformer Encoder->classificationï¼Œè€ŒQuestionAnsweringéœ€è¦Embedding->Transofrmer Encoder->QAã€‚å…¶ä¸­çš„Classification Layeråªéœ€è¦è¾“å‡º2ä¸ªlogitç”¨æ¥åšäºŒåˆ†ç±»ï¼Œè€ŒQAéœ€è¦è¾“å‡º2ä¸ªæ•´æ•°ä»£è¡¨Answerçš„startå’Œendä¸‹æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc386406",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 æŸ¥çœ‹æ¨¡å‹ç»“æ„å¹¶ç†è§£FineTune\n",
    "æˆ‘ä»¬å°è¯•ç”¨ä¸€ä¸ªbertæ¨¡å‹æ¥åšQuestionAnseringï¼Œå¯ä»¥çœ‹åˆ°HFçš„Warningä¿¡æ¯ï¼šåŸé¢„è®­ç»ƒæ¨¡å‹çš„ç½‘ç»œç»“æ„ä¸­çš„åˆ†ç±»layerä¼šè¢«æŠ›å¼ƒï¼ŒåŒæ—¶æ–°å¢ä¸€ä¸ªæ²¡æœ‰åˆå§‹åŒ–çš„QA layerã€‚è¿™å°±æ„å‘³ç€è¿™ä¸ªæ¨¡å‹å¿…é¡»è¢«FineTuneè®­ç»ƒä¹‹åæ‰èƒ½è¢«ä½¿ç”¨ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°è¿™ä¸ªæ¨¡å‹çš„è¯¦ç»†ç¥ç»ç½‘ç»œç»“æ„ï¼š\n",
    "- æœ€åº•å±‚æ˜¯Embeddingå±‚ï¼Œæ”¯æŒ30522ä¸ªå•è¯ï¼ˆtokenï¼‰ï¼Œæ¯ä¸ªå•è¯å¯¹åº”çš„Embeddingæ˜¯ä¸€ä¸ª768ç»´çš„å‘é‡ã€‚\n",
    "- ä¹‹åæ˜¯ä¸€ä¸ªTransfomerï¼Œç”±6ä¸ªTransformerBlockæ„æˆï¼Œæ¯ä¸€ä¸ªTransformerBlockæœ‰MultiHeadSelfAttentionï¼Œ LayerNormï¼ŒFFNä¸‰éƒ¨åˆ†ã€‚æœ€åè¾“å‡ºä¸€ä¸ª768ç»´çš„å‘é‡\n",
    "- å¢åŠ äº†ä¸€ä¸ªæ–°çš„Layerå«QA Outputï¼›æŠŠä¸€ä¸ª768ç»´çš„å‘é‡è½¬æ¢ä¸º2ä¸ªæ•°å­—ï¼Œåˆ†åˆ«ä»£è¡¨Answerçš„startå’Œendä¸‹æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "321b3e4b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertForQuestionAnswering: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed04511",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 é¢„è®­ç»ƒç¬¬ä¸€æ­¥ï¼šåŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹\n",
    "æˆ‘ä»¬é€‰æ‹©æ’åç¬¬ä¸€çš„ä¸­æ–‡ç¿»è¯‘åˆ°è‹±æ–‡çš„æ¨¡å‹æ¥åšFineTuneï¼šHelsinki-NLP/opus-mt-zh-enï¼ˆ[é“¾æ¥](https://huggingface.co/Helsinki-NLP/opus-mt-zh-en)ï¼‰ã€‚æˆ‘ä»¬å°†åœ¨è¿™ä¸ªæ¨¡å‹åŸºç¡€ä¹‹ä¸ŠåŠ å…¥è‡ªå·±çš„è¯­æ–™è¿›ä¸€æ­¥FineTuneï¼Œä¹Ÿå°±æ˜¯ä¿ç•™é¢„è®­ç»ƒçš„æ¨¡å‹ç»“æ„ï¼Œåªæ˜¯å¯¹å…¶ä¸­æƒé‡ï¼ˆweightsï¼‰åšè®­ç»ƒã€‚\n",
    "\n",
    "æˆ‘ä»¬åŠ è½½æ¨¡å‹ï¼Œå¹¶çœ‹ä¸€ä¸‹è¿™ä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„æ•ˆæœï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "feaab1a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.WARN)\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8603030c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': \"Hello. It's a nice day.\"}, {'translation_text': 'Deep learning is a new approach.'}, {'translation_text': 'The importance of mathematics speaks for itself.'}, {'translation_text': \"I don't know what I'm talking about.\"}]\n",
      "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”å¾ˆå¥½ ===> Hello. It's a nice day.\n",
      "æ·±åº¦å­¦ä¹ æ˜¯ä¸€ç§æ–°çš„æ–¹æ³• ===> Deep learning is a new approach.\n",
      "æ•°å­¦çš„é‡è¦æ€§ä¸è¨€è€Œå–» ===> The importance of mathematics speaks for itself.\n",
      "ä¸æ˜è§‰å‰ ===> I don't know what I'm talking about.\n"
     ]
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”å¾ˆå¥½\",\n",
    "    \"æ·±åº¦å­¦ä¹ æ˜¯ä¸€ç§æ–°çš„æ–¹æ³•\",\n",
    "    \"æ•°å­¦çš„é‡è¦æ€§ä¸è¨€è€Œå–»\",\n",
    "    \"ä¸æ˜è§‰å‰\",\n",
    "    #'â€œè™½ä¸æ˜ï¼Œä½†è§‰å‰â€ï¼Œç½‘ç»œæµè¡Œè¯ï¼Œç®€ç§°â€œä¸æ˜è§‰å‰â€ï¼Œè¡¨ç¤ºâ€œè™½ç„¶ä¸æ˜ç™½ä½ åœ¨è¯´ä»€ä¹ˆï¼Œä½†å¥½åƒå¾ˆå‰å®³çš„æ ·å­ã€‚'\n",
    "]\n",
    "results = translator(sequences)\n",
    "print(results)\n",
    "for source, target in zip(sequences, results):\n",
    "    print(source, \"===>\", target[\"translation_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4216fd5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¯ä»¥çœ‹åˆ°å½“å‰çš„ç¿»è¯‘æ•ˆæœå¾ˆä¸é”™ï¼Œå¹¶ä¸”è¿˜å¸®æˆ‘ä»¬æŠŠå¥å·éƒ½åŠ ä¸Šäº†ğŸ˜„ï¼å…¶ä¸­çš„â€œä¸è¨€è€Œå–»â€çš„ç¿»è¯‘æ›´æ˜¯éå¸¸åœ°é“ã€‚ä½†æ˜¯å¯¹â€œä¸æ˜è§‰å‰â€è¿™ä¸ªç½‘ç»œè¯æ±‡çš„ç†è§£ä¸å¤Ÿå‡†ç¡®ï¼Œæˆ‘ä»¬ä¸‹é¢è¦å®Œæˆçš„FineTuneä»»åŠ¡å°±æ˜¯è®©æ¨¡å‹è®°ä½â€œä¸æ˜è§‰å‰â€çš„è‹±æ–‡å¥å­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f79aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3 é¢„è®­ç»ƒç¬¬äºŒæ­¥ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®\n",
    "å¦‚æœHF Hubä¸­å·²ç»æœ‰æˆ‘ä»¬éœ€è¦çš„æ•°æ®é›†ï¼Œå¯ä»¥ç”¨datasetsè¿™ä¸ªåº“æ¥ç›´æ¥loadï¼›ä¹Ÿå¯ä»¥æå‰pushåˆ°HF Hubä¹‹åå†loadã€‚å¦‚æœä¸å¸Œæœ›pushåˆ°HFï¼Œä¹Ÿå¯ä»¥æŠŠè®­ç»ƒæ•°æ®æ”¾åˆ°æœ¬åœ°æ¥Loadã€‚ ä¸ºäº†æ–¹ä¾¿æ¼”ç¤ºï¼Œæˆ‘ä»¬ç”¨å†…å­˜ä¸­æ•°æ®æ¥æ„é€ ä¸€ä¸ªdatasetï¼ˆå‚è€ƒ[é“¾æ¥](https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html)ï¼‰ï¼›å…¶ä¸­å°±æ˜¯â€œä¸æ˜è§‰å‰â€çš„è‹±æ–‡ç¿»è¯‘è¿™ä¸€ä¸ªæ ·æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "80a5ed96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "source_sentences = [\"ä¸æ˜è§‰å‰\"]\n",
    "target_sentences=[\"It's not clear what you're talking about, but it looks like it's pretty good\"]\n",
    "\n",
    "inputs = tokenizer(source_sentences, max_length=50, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(target_sentences, return_tensors='pt', padding=True)\n",
    "inputs['decoder_input_ids']=labels['input_ids']\n",
    "inputs['decoder_attention_mask']=labels['attention_mask']\n",
    "inputs['labels']=labels['input_ids']\n",
    "\n",
    "dataset = Dataset.from_dict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa8041",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4 é¢„è®­ç»ƒç¬¬ä¸‰æ­¥ï¼šå‡†å¤‡è®­ç»ƒçš„å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "869c1394",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mymodels\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=6,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=False,\n",
    "    prediction_loss_only=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3d215",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.5 é¢„è®­ç»ƒç¬¬å››æ­¥ï¼šå¼€å§‹è®­ç»ƒ\n",
    "HFæä¾›äº†Trainerç±»æ¥è¾…åŠ©è®­ç»ƒï¼ŒHFä¹Ÿæ”¯æŒç”¨Tensorflowæˆ–è€…PyTorchæ¥å®Œæˆè®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "07b96650",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.3808326721191406, metrics={'train_runtime': 0.6848, 'train_samples_per_second': 4.381, 'train_steps_per_second': 4.381, 'total_flos': 3972464640.0, 'train_loss': 0.3808326721191406, 'epoch': 3.0})"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca339e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.6 ä½¿ç”¨FineTuneä¹‹åçš„æ¨¡å‹æŸ¥çœ‹ç¿»è¯‘æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c077578a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Everyone was shocked when I heard the news.'},\n",
       " {'translation_text': \"It's not clear what you're talking about, but it looks like it's pretty good\"}]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pipeline=pipeline('translation', model=model, tokenizer=tokenizer)\n",
    "new_pipeline([\"å¬åˆ°è¿™ä¸ªæ¶ˆæ¯ä¹‹åï¼Œæ‰€æœ‰äººéƒ½éœ‡æƒŠäº†\", \"ä¸æ˜è§‰å‰\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db924019",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.7 ä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "15d04c9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "85f5d7d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 296M\n",
      "-rw-rw-rw- 1 root root 1.4K Jun 17 11:35 config.json\n",
      "-rw-rw-rw- 1 root root 296M Jun 17 11:35 pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328865a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. æ€»ç»“\n",
    "HuggingFaceæä¾›äº†å¤§é‡çš„é¢„è®­ç»ƒæ¨¡å‹ä¾›ç®—æ³•å·¥ç¨‹å¸ˆä½¿ç”¨ï¼ŒåŸºäºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åšæ¨ç†æˆ–é¢„æµ‹ï¼Œä¹Ÿå¯ä»¥è¿›ä¸€æ­¥FineTuneæ¥é€‚åº”è‡ªå·±çš„ä¸šåŠ¡æ•°æ®ã€‚è€ŒHF python SDKæä¾›äº†éå¸¸å‹å¥½çš„interfaceï¼Œæœ€å¸¸ç”¨çš„æ˜¯pipelineã€modelã€tokeninzerã€trainerç­‰ã€‚"
   ]
  }
 ],
 "metadata": {
  "dsw_sample": {
   "buildId": "450",
   "pipeline": "pai-dsw-examples-master"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
