{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07c241d",
   "metadata": {
    "id": "28783cd2-4274-4769-97b2-85c0b924135e",
    "index": 0.625
   },
   "source": [
    "## 1.下载llama项目，并安装相关python依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091bf50-fb8c-4f43-a911-bf71256ed9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://ghproxy.com/https://github.com/facebookresearch/llama.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61e6a2c6-8224-4e4b-93c2-72070bd189ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T05:42:17.015203Z",
     "iopub.status.busy": "2023-07-06T05:42:17.014811Z",
     "iopub.status.idle": "2023-07-06T05:42:23.649575Z",
     "shell.execute_reply": "2023-07-06T05:42:23.648908Z",
     "shell.execute_reply.started": "2023-07-06T05:42:17.015179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: torch in /home/pai/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: fairscale in /home/pai/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.4.13)\n",
      "Requirement already satisfied: fire in /home/pai/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: sentencepiece in /home/pai/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.1.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/pai/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/pai/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/pai/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/pai/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/pai/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /home/pai/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 1)) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/pai/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 1)) (0.38.4)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/pai/lib/python3.9/site-packages (from fairscale->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: termcolor in /home/pai/lib/python3.9/site-packages (from fire->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: six in /home/pai/lib/python3.9/site-packages (from fire->-r requirements.txt (line 3)) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Obtaining file:///mnt/workspace/llama\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: llama\n",
      "  Attempting uninstall: llama\n",
      "    Found existing installation: llama 0.0.0\n",
      "    Uninstalling llama-0.0.0:\n",
      "      Successfully uninstalled llama-0.0.0\n",
      "  Running setup.py develop for llama\n",
      "Successfully installed llama-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd llama && pip install -r requirements.txt && pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c2c20",
   "metadata": {
    "id": "84f978b8-a00a-437d-9cd6-68559a2ee734",
    "index": 0.9375
   },
   "source": [
    "## 2.下载llama-7B模型文件,我在huggingface找到了一个 nyanko7/LLaMA-7B,官方的是这个  huggyllama/llama-7b，但是不知道怎么用\n",
    "或者wget下载，比较慢\n",
    "```\n",
    "wget https://agi.gpt4.org/llama/LLaMA/tokenizer.model -O ./tokenizer.model\n",
    "wget https://agi.gpt4.org/llama/LLaMA/tokenizer_checklist.chk -O ./tokenizer_checklist.chk\n",
    "wget https://agi.gpt4.org/llama/LLaMA/7B/consolidated.00.pth -O ./7B/consolidated.00.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/7B/params.json -O ./7B/params.json\n",
    "wget https://agi.gpt4.org/llama/LLaMA/7B/checklist.chk -O ./7B/checklist.chk\n",
    "wget https://agi.gpt4.org/llama/LLaMA/13B/consolidated.00.pth -O ./13B/consolidated.00.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/13B/consolidated.01.pth -O ./13B/consolidated.01.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/13B/params.json -O ./13B/params.json\n",
    "wget https://agi.gpt4.org/llama/LLaMA/13B/checklist.chk -O ./13B/checklist.chk\n",
    "wget https://agi.gpt4.org/llama/LLaMA/30B/consolidated.00.pth -O ./30B/consolidated.00.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/30B/consolidated.01.pth -O ./30B/consolidated.01.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/30B/consolidated.02.pth -O ./30B/consolidated.02.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/30B/consolidated.03.pth -O ./30B/consolidated.03.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/30B/params.json -O ./30B/params.json\n",
    "wget https://agi.gpt4.org/llama/LLaMA/30B/checklist.chk -O ./30B/checklist.chk\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.00.pth -O ./65B/consolidated.00.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.01.pth -O ./65B/consolidated.01.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.02.pth -O ./65B/consolidated.02.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.03.pth -O ./65B/consolidated.03.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.04.pth -O ./65B/consolidated.04.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.05.pth -O ./65B/consolidated.05.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.06.pth -O ./65B/consolidated.06.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/consolidated.07.pth -O ./65B/consolidated.07.pth\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/params.json -O ./65B/params.json\n",
    "wget https://agi.gpt4.org/llama/LLaMA/65B/checklist.chk -O ./65B/checklist.chk\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e0f69-118e-4625-ab05-f45287ebcd67",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!python download-model.py nyanko7/LLaMA-7B\n",
    "!mkdir -p models/nyanko7_LLaMA-7B/7B\n",
    "!mv models/nyanko7_LLaMA-7B/consolidated.00.pth models/nyanko7_LLaMA-7B/7B\n",
    "!mv models/nyanko7_LLaMA-7B/params.json models/nyanko7_LLaMA-7B/7B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a08974d",
   "metadata": {
    "id": "db0b4de7-9606-41a6-81aa-e793fca9cdc4",
    "index": 0.96875
   },
   "source": [
    "## 3.执行example.py获取模型输出结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fdc8b42a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-06T05:49:24.971384Z",
     "iopub.status.busy": "2023-07-06T05:49:24.971010Z",
     "iopub.status.idle": "2023-07-06T05:50:01.411937Z",
     "shell.execute_reply": "2023-07-06T05:50:01.411277Z",
     "shell.execute_reply.started": "2023-07-06T05:49:24.971361Z"
    },
    "id": "20f856f5-f9b4-4581-898c-4d3551db9312",
    "index": 1,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loading\n",
      "^C\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2112 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/workspace/llama/example.py\", line 97, in <module>\n",
      "    fire.Fire(main)\n",
      "  File \"/home/pai/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "  File \"/home/pai/lib/python3.9/site-packages/fire/core.py\", line 475, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "  File \"/home/pai/lib/python3.9/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "  File \"/mnt/workspace/llama/example.py\", line 78, in main\n",
      "    generator = load(\n",
      "  File \"/mnt/workspace/llama/example.py\", line 47, in load\n",
      "    checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
      "  File \"/home/pai/lib/python3.9/site-packages/torch/serialization.py\", line 809, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/pai/lib/python3.9/site-packages/torch/serialization.py\", line 1172, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/pai/lib/python3.9/site-packages/torch/serialization.py\", line 1142, in persistent_load\n",
      "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "  File \"/home/pai/lib/python3.9/site-packages/torch/serialization.py\", line 1112, in load_tensor\n",
      "    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!cd llama && TARGET_FOLDER=../models/nyanko7_LLaMA-7B && MODEL_SIZE=7B && torchrun --nproc_per_node 1 example.py --ckpt_dir $TARGET_FOLDER/$MODEL_SIZE --tokenizer_path $TARGET_FOLDER/tokenizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8d45b-edc2-4ad7-aeb0-4bf010fe1190",
   "metadata": {},
   "source": [
    "引用\n",
    "\n",
    ">\n",
    "* https://juejin.cn/post/7209825720385781819\n",
    "* https://github.com/facebookresearch/llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0526a-5773-463c-9b51-fd31c602e98f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python download-model.py openlm-research/open_llama_7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54513f-04d0-4743-952e-d2156e88c696",
   "metadata": {},
   "source": [
    "配置transformer依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "94ab1ffa-bb4a-4771-97d1-15fb98efd9dc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-06T05:58:50.676697Z",
     "iopub.status.busy": "2023-07-06T05:58:50.676365Z",
     "iopub.status.idle": "2023-07-06T05:58:53.539652Z",
     "shell.execute_reply": "2023-07-06T05:58:53.539036Z",
     "shell.execute_reply.started": "2023-07-06T05:58:50.676672Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: transformers in /home/pai/lib/python3.9/site-packages (4.31.0.dev0)\n",
      "Requirement already satisfied: datasets in /home/pai/lib/python3.9/site-packages (2.13.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/pai/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/pai/lib/python3.9/site-packages (from transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/pai/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pai/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pai/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/pai/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in /home/pai/lib/python3.9/site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/pai/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pai/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /home/pai/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/pai/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/pai/lib/python3.9/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/pai/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/pai/lib/python3.9/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: aiohttp in /home/pai/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: xxhash in /home/pai/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/pai/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pai/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/pai/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pai/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pai/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/pai/lib/python3.9/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/pai/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pai/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pai/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/pai/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e67f1-85f0-4699-b081-2c3e1b83b684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c75ca3-3d97-44c2-b2e7-c0f1afa5245f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f195106-5f30-49d8-bcf5-2fb29f70d2ba",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-06T05:56:36.902822Z",
     "iopub.status.busy": "2023-07-06T05:56:36.902477Z",
     "iopub.status.idle": "2023-07-06T05:57:36.198688Z",
     "shell.execute_reply": "2023-07-06T05:57:36.198046Z",
     "shell.execute_reply.started": "2023-07-06T05:56:36.902798Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:52<00:00, 26.33s/it]\n",
      "/mnt/workspace/transformers/src/transformers/generation/utils.py:1462: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "<s>Q: What is the largest animal?\n",
      "A: The largest animal is the blue whale.\n",
      "Q: What is the smallest animal?\n",
      "A: The smallest animal is the bee.\n",
      "Q: What is\n"
     ]
    }
   ],
   "source": [
    "!python openllama.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
