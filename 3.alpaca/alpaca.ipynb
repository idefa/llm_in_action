{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4630a29b-2138-4c80-8b59-c1b62de26e07",
   "metadata": {},
   "source": [
    "# 轻量微调和推理Alpaca实践\n",
    "当前的Alpaca模型是在Self-Instruct论文中使用的技术生成的52K条指令数据，从7B LLaMA模型微调而来，并进行了一些修改。本文将以Alpaca为例，为您介绍如何在PAI-DSW中训练微调推理Alpaca。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e563a5",
   "metadata": {},
   "source": [
    "## 运行环境要求\n",
    "\n",
    "Python环境3.9以上 and GPU机器显存32G以上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71b0c8-55c4-4640-a9be-1b2c70ec5daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T05:40:47.274666Z",
     "iopub.status.busy": "2023-04-06T05:40:47.274347Z",
     "iopub.status.idle": "2023-04-06T05:40:47.285358Z",
     "shell.execute_reply": "2023-04-06T05:40:47.284089Z",
     "shell.execute_reply.started": "2023-04-06T05:40:47.274621Z"
    }
   },
   "source": [
    "## 准备工作\n",
    "#### 下载stanford_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f490432-277a-4c36-bcee-cf00525fe4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/alpaca/stanford_alpaca.tgz\n",
    "!tar -xvf stanford_alpaca.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f2d12-badf-4778-aedb-fd77008cc20c",
   "metadata": {},
   "source": [
    "### 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c7052-d8d0-4dea-9fc6-b3db50baecae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd stanford_alpaca &&  echo y | pip uninstall torch &&  echo y | pip uninstall torchvision && pip install -r requirements.txt && pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b0cdc-9beb-4775-ba14-1bfbfc2ba3f8",
   "metadata": {},
   "source": [
    "#### 配置transformer依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d871bf5a-e266-4e62-9fa1-4bc54b2860ee",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://ghproxy.com/https://github.com/huggingface/transformers.git && \\\n",
    "cd transformers && \\\n",
    "git checkout 165dd6dc916a43ed9b6ce8c1ed62c3fe8c28b6ef && \\\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38c43a-e2e6-4132-9988-e903f0e5d2c5",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5d5ab-31aa-4bdf-aaee-f380c02d323c",
   "metadata": {},
   "source": [
    "数据格式如下，如需使用自己的数据进行微调可以转化成如下形式：</br>\n",
    "\"instruction\"：用于描述模型应该执行的任务</br>\n",
    "\"input\" ： 任务的可选上下文或输入。例如，当指令是“总结以下文章”时，输入就是文章。</br>\n",
    "\"output\" ：需要模型输出的答案</br>\n",
    "\n",
    "格式如下\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"instruction\": \"Give three tips for staying healthy.\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d66993-d579-4b0d-aeb9-227a8c6213ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T03:16:38.901469Z",
     "iopub.status.busy": "2023-07-06T03:16:38.901121Z",
     "iopub.status.idle": "2023-07-06T03:16:39.282010Z",
     "shell.execute_reply": "2023-07-06T03:16:39.281476Z",
     "shell.execute_reply.started": "2023-07-06T03:16:38.901449Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-06 11:16:39--  https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/alpaca/alpaca_data.json\n",
      "Resolving atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)... 47.101.88.27\n",
      "Connecting to atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)|47.101.88.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8799 (8.6K) [application/json]\n",
      "Saving to: ‘alpaca_data.json’\n",
      "\n",
      "alpaca_data.json    100%[===================>]   8.59K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-06 11:16:39 (99.4 MB/s) - ‘alpaca_data.json’ saved [8799/8799]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 下载数据集，如有重名文件，先将文件夹中的重名文件重命名。\n",
    "!wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/alpaca/alpaca_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a2150-f8f3-4a06-890d-f5b0224fe229",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d8c880",
   "metadata": {},
   "source": [
    "#### 准备权重\n",
    "在训练之前，我们需要预先下载预训练权重，该权重过大(12G)，下载，解压需较长时间，大约15分钟左右，保险建议复制下面命令（去掉！）前往**终端**运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56283fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T03:20:44.312361Z",
     "iopub.status.busy": "2023-07-06T03:20:44.312007Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-06 11:20:44--  https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/alpaca/llama-7b-hf.tar.gz\n",
      "Resolving atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)... 47.101.88.27\n",
      "Connecting to atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)|47.101.88.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12432047721 (12G) [application/gzip]\n",
      "Saving to: ‘llama-7b-hf.tar.gz’\n",
      "\n",
      "llama-7b-hf.tar.gz   59%[==========>         ]   6.83G  23.2MB/s    eta 4m 54s "
     ]
    }
   ],
   "source": [
    "!wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/alpaca/llama-7b-hf.tar.gz && tar -xvf llama-7b-hf.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68c293",
   "metadata": {},
   "source": [
    "#### 参数调节\n",
    "下载完预训练权重后，我们需要改下参数适配机器微调，不然容易发生显存过载，我们可以修改部分参数来保证在较小显存和单卡上也可以测试</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d61185",
   "metadata": {},
   "source": [
    "根据预训练路径找到对应的config.json文件</br>\n",
    "并按照下面的参数修改  **./llama-7b-hf/**  路径下面的**config.json**文件</br>\n",
    "**model_max_length=4**和**num_hidden_layers=4**等参数以保证较小显存也可以训练\n",
    "```json\n",
    "{\n",
    "    \"architectures\": [\"LLaMAForCausalLM\"], \n",
    "    \"bos_token_id\": 0, \n",
    "    \"eos_token_id\": 1, \n",
    "    \"hidden_act\": \"silu\", \n",
    "    \"hidden_size\": 4096, \n",
    "    \"intermediate_size\": 11008, \n",
    "    \"initializer_range\": 0.02, \n",
    "    \"max_sequence_length\": 4, \n",
    "    \"model_type\": \"llama\", \n",
    "    \"num_attention_heads\": 32, \n",
    "    \"num_hidden_layers\": 4, \n",
    "    \"pad_token_id\": -1, \n",
    "    \"rms_norm_eps\": 1e-06, \n",
    "    \"torch_dtype\": \"float16\", \n",
    "    \"transformers_version\": \"4.27.0.dev0\", \n",
    "    \"use_cache\": true, \n",
    "    \"vocab_size\": 32000\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14a863-24ee-4139-bf66-0fc1ce0ad06e",
   "metadata": {},
   "source": [
    "#### 训练阶段\n",
    "训练前，把**model_name_or_path**改为我们预训练权重的路径，训练批次**num_train_epochs**参数可自行修改，训练阶段中间会有询问是否要**wandb**日志保存的阶段，所以我们建议复制下面复制到**终端**运行为好，出现**wandb**选择，我们直接填3即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16f9d04-eb16-4543-b911-a92fe67c71c2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 执行训练指令\n",
    "!torchrun --nproc_per_node=1 --master_port=29588 ./stanford_alpaca/train.py \\\n",
    " --model_name_or_path \"./llama-7b-hf\" \\\n",
    " --data_path ./alpaca_data.json \\\n",
    " --bf16 False \\\n",
    " --output_dir /models/alpaca-2 \\\n",
    " --num_train_epochs 1 \\\n",
    " --per_device_train_batch_size 1 \\\n",
    " --per_device_eval_batch_size 1 \\\n",
    " --gradient_accumulation_steps 8 \\\n",
    " --evaluation_strategy \"no\" \\\n",
    " --save_strategy \"steps\" \\\n",
    " --save_steps 2000 \\\n",
    " --save_total_limit 1 \\\n",
    " --learning_rate 2e-5 \\\n",
    " --model_max_length 4 \\\n",
    " --weight_decay 0. \\\n",
    " --warmup_ratio 0.03 \\\n",
    " --lr_scheduler_type \"cosine\" \\\n",
    " --logging_steps 1 \\\n",
    " --fsdp \"full_shard auto_wrap\" \\\n",
    " --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n",
    " --tf32 False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f48e6c-8504-42d5-9ce0-594d6ab5d13f",
   "metadata": {},
   "source": [
    "训练代码顺利执行情况如下图所示。</br>\n",
    "\n",
    "\n",
    "![png](./img/pp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487bb8e1-e7eb-4030-a66c-ee3855677b18",
   "metadata": {},
   "source": [
    "## 推理阶段\n",
    "可以用以下代码进行推理</br>\n",
    "在notebook推理前，建议**重启**notebook，防止python环境未连接上而出现包导入不了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f38453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizers = transformers.LlamaTokenizer.from_pretrained(\"./models/alpaca-2\")\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(\"./models/alpaca-2\").cuda()\n",
    "model.eval()\n",
    "def gen(req):\n",
    "    batch = tokenizers(req, return_tensors='pt', add_special_tokens=False)\n",
    "    batch = {k: v.cuda() for k, v in batch.items()}\n",
    "    full_completion = model.generate(inputs=batch[\"input_ids\"],\n",
    "                                    attention_mask=batch[\"attention_mask\"],\n",
    "                                    temperature=0.7,\n",
    "                                    top_p=0.9,\n",
    "                                    do_sample=True,\n",
    "                                    num_beams=1,\n",
    "                                    max_new_tokens=600,\n",
    "                                    eos_token_id=tokenizers.eos_token_id,\n",
    "                                    pad_token_id=tokenizers.pad_token_id)\n",
    "    print(tokenizers.decode(full_completion[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bf414",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(\"List all Canadian provinces in alphabetical order.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6cecc6",
   "metadata": {},
   "source": [
    "也可以用以下文件进行推理</br>\n",
    "记得修改gen.py文件里面代码的模型路径，使用上述训练**output_dir**参数的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget  https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/alpaca/gen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gen.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276026b",
   "metadata": {},
   "source": [
    "## 试玩模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e204e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import json\n",
    "import transformers\n",
    "\n",
    "tokenizers = transformers.LlamaTokenizer.from_pretrained(\"./models/alpaca-2\")\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(\"./models/alpaca-2\").cuda()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def inference(text):\n",
    "    batch  = tokenizers(text, return_tensors=\"pt\", add_special_tokens=False)                                                                                                                                                      \n",
    "    batch = {k: v.cuda() for k, v in batch.items()}                                                                                                                                                                              \n",
    "    full_completion = model.generate(inputs=batch[\"input_ids\"],                                                                                                                                                                  \n",
    "                                     attention_mask=batch[\"attention_mask\"],                                                                                                                                                      \n",
    "                                     temperature=0.7,                                                                                                                                                                             \n",
    "                                     top_p=0.9,                                                                                                                                                                                   \n",
    "                                     do_sample=True,                                                                                                                                                                              \n",
    "                                     num_beams=1,                                                                                                                                                                                 \n",
    "                                     max_new_tokens=600,                                                                                                                                                                          \n",
    "                                     eos_token_id=tokenizers.eos_token_id,                                                                                                                                                        \n",
    "                                     pad_token_id=tokenizers.pad_token_id)                                                                                                                                                                                                                                                                                                                                                              \n",
    "    print(tokenizers.decode(full_completion[0]))\n",
    "    return tokenizers.decode(full_completion[0])\n",
    "\n",
    "demo = gr.Blocks()\n",
    "with demo:\n",
    "    input_prompt = gr.Textbox(label=\"请输入需求\", \n",
    "                                value=\"帮我写一篇安全检查的新闻稿件。\",\n",
    "                                lines=6)\n",
    "    generated_txt = gr.Textbox(lines=6)\n",
    "\n",
    "    b1 = gr.Button(\"发送\")\n",
    "    b1.click(inference, inputs=[input_prompt], outputs=generated_txt) \n",
    "\n",
    "demo.launch(enable_queue=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "dsw_sample": {
   "buildId": "450",
   "pipeline": "pai-dsw-examples-master"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
